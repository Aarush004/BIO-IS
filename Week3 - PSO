import numpy as np
import random
import matplotlib.pyplot as plt

# Set seeds for reproducibility
random.seed(42)
np.random.seed(42)

# --- Objective Function: Sphere ---
def sphere_function(position):
    """Sphere function: f(x) = sum(x_i^2). Minimum is 0 at x = [0,...,0]."""
    return np.sum(position ** 2)

# --- PSO Algorithm ---
def pso_optimizer(
    objective_func,
    num_particles=30,
    dimensions=2,
    search_range=(-10, 10),
    max_iterations=100,
    w=0.729,   # Inertia weight
    c1=1.4944, # Cognitive coefficient
    c2=1.4944  # Social coefficient
):
    min_bound, max_bound = search_range

    # Initialize positions and velocities
    positions = np.random.uniform(min_bound, max_bound, (num_particles, dimensions))
    velocities = np.random.uniform(-1, 1, (num_particles, dimensions))

    # Initialize personal and global bests
    pbest_positions = positions.copy()
    pbest_scores = np.array([objective_func(p) for p in positions])
    gbest_index = np.argmin(pbest_scores)
    gbest_position = pbest_positions[gbest_index].copy()
    gbest_score = pbest_scores[gbest_index]

    history = [(gbest_score, gbest_position.copy())]

    for iteration in range(max_iterations):
        # Update personal bests
        for i in range(num_particles):
            score = objective_func(positions[i])
            if score < pbest_scores[i]:
                pbest_scores[i] = score
                pbest_positions[i] = positions[i].copy()

        # Update global best
        current_best_index = np.argmin(pbest_scores)
        if pbest_scores[current_best_index] < gbest_score:
            gbest_score = pbest_scores[current_best_index]
            gbest_position = pbest_positions[current_best_index].copy()

        # Record progress
        history.append((gbest_score, gbest_position.copy()))

        # Update velocities and positions
        r1 = np.random.rand(num_particles, dimensions)
        r2 = np.random.rand(num_particles, dimensions)

        inertia = w * velocities
        cognitive = c1 * r1 * (pbest_positions - positions)
        social = c2 * r2 * (gbest_position - positions)

        velocities = inertia + cognitive + social
        positions += velocities
        positions = np.clip(positions, min_bound, max_bound)

        print(f"Iteration {iteration+1}/{max_iterations}: GBest Score = {gbest_score:.4e}")

    return gbest_position, gbest_score, history

# --- Example Run & Visualization ---
def run_pso_example():
    search_range = (-5.12, 5.12)
    max_iter = 100

    best_position, best_score, history = pso_optimizer(
        objective_func=sphere_function,
        num_particles=30,
        dimensions=2,
        search_range=search_range,
        max_iterations=max_iter
    )

    print("\n--- Results ---")
    print(f"Best Position: {best_position}")
    print(f"Minimum Score: {best_score:.6e}")

    # Convergence Plot
    scores = [item[0] for item in history]
    plt.figure(figsize=(10, 5))

    plt.subplot(1, 2, 1)
    plt.plot(scores, color='darkorange', linewidth=2)
    plt.title('PSO Convergence')
    plt.xlabel('Iteration')
    plt.ylabel('Best Score (log scale)')
    plt.yscale('log')
    plt.grid(True, which="both", ls="--")

    # 2D Visualization (only if dimensions == 2)
    if len(best_position) == 2:
        plt.subplot(1, 2, 2)
        x = np.linspace(search_range[0], search_range[1], 100)
        y = np.linspace(search_range[0], search_range[1], 100)
        X, Y = np.meshgrid(x, y)
        Z = X**2 + Y**2
        plt.contourf(X, Y, Z, levels=50, cmap='viridis')
        plt.plot(best_position[0], best_position[1], 'r*', markersize=15, label='Final GBest')
        plt.title('2D Search Space')
        plt.xlabel('X')
        plt.ylabel('Y')
        plt.legend()

    plt.tight_layout()
    plt.show()

# --- Run ---
if __name__ == '__main__':
    run_pso_example()
